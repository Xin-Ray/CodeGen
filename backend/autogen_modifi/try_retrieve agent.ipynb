{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create group with content assistant\n"
     ]
    }
   ],
   "source": [
    "# Autogen Imports\n",
    "import autogen\n",
    "from autogen.agentchat.groupchat import GroupChat\n",
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "from autogen.agentchat.contrib.llava_agent import LLaVAAgent\n",
    "from flask_socketio import emit\n",
    "\n",
    "# Data Processing and Utility Libraries\n",
    "from chromadb.utils import embedding_functions\n",
    "import logging\n",
    "import os\n",
    "import chromadb\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': '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',\n",
    "        # \"model\": \"mistral-7b\",\n",
    "        # \"base_url\": \"http://localhost:1234/v1\",\n",
    "        # # \"api_type\": \"openai\",\n",
    "        # \"api_key\": \"\",\n",
    "    }]\n",
    "\n",
    "config_list_gpt4 = {\n",
    "    \"cache_seed\": 42,  # change the cache_seed for different trials\n",
    "    \"temperature\": 0,\n",
    "    \"config_list\": config_list,\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "\n",
    "termination_msg = lambda x: isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()\n",
    "\n",
    "\n",
    "boss_aid = RetrieveUserProxyAgent(\n",
    "    name=\"Boss_Assistant\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=\"Assistant who has extra content retrieval power for solving difficult problems.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=3,\n",
    "    retrieve_config={\n",
    "        \"task\": \"code\",\n",
    "        \"docs_path\": \"./tmp/MedVetGPT.pdf\",\n",
    "        \"chunk_token_size\": 1000,\n",
    "        \"model\": config_list_gpt4[\"config_list\"][0][\"model\"],\n",
    "        \"collection_name\": \"groupchat\",\n",
    "        \"get_or_create\": True,\n",
    "    },\n",
    "    code_execution_config=False,  # we don't want to execute code in this case.\n",
    ")\n",
    "\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Senior_Python_Engineer\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=\"You are a senior python engineer. Reply `TERMINATE` in the end when everything is done.\",\n",
    "    llm_config=config_list_gpt4,\n",
    ")\n",
    "\n",
    "pm = autogen.AssistantAgent(\n",
    "    name=\"Product_Manager\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=\"You are a product manager. Reply `TERMINATE` in the end when everything is done.\",\n",
    "    llm_config=config_list_gpt4,\n",
    ")\n",
    "\n",
    "reviewer = autogen.AssistantAgent(\n",
    "    name=\"Code_Reviewer\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=\"You are a code reviewer. Reply `TERMINATE` in the end when everything is done.\",\n",
    "    llm_config=config_list_gpt4,\n",
    ")\n",
    "print('create group with content assistant')\n",
    "agent_list = [boss_aid, coder, pm, reviewer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = GroupChat(agents=agent_list, messages=[], max_round=10,speaker_selection_method=\"round_robin\")\n",
    "    \n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, \n",
    "                                    llm_config=config_list_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM = \"please summarize the content of this pdf file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_tokens is too small to fit a single line of text. Breaking this line:\n",
      "\tVetMedGPT: Generative Pre-trained Transformer for Enhanced Animal ...\n",
      "Failed to split docs with must_break_at_empty_line being True, set to False.\n",
      "Number of requested results 20 is greater than number of elements in index 4, updating n_results = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to create collection.\n",
      "doc_ids:  [['doc_1', 'doc_0', 'doc_3', 'doc_2']]\n",
      "\u001b[32mAdding doc_id doc_1 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_0 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_3 to context.\u001b[0m\n",
      "\u001b[33mBoss_Assistant\u001b[0m (to chat_manager):\n",
      "\n",
      "You're a retrieve augmented coding assistant. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user.\n",
      "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
      "For code generation, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "User's question is: please summarize the content of this pdf file.\n",
      "\n",
      "Context is: ble of processing and interpreting complex veterinary ter-\n",
      "minologies. Our motivation is rooted in revolutionizing the\n",
      "ways in which veterinary information is comprehended, fa-\n",
      "cilitating enhanced clinical decision-making, enabling thor-\n",
      "ough research literature analysis, and supporting educa-\n",
      "tional endeavors within the field. By addressing these criti-\n",
      "cal needs, VetMedGPT aims to significantly advance veteri-\n",
      "nary medicine by facilitating accurate identification, com-\n",
      "prehensive understanding, and proactive management of in-\n",
      "tricate medical conditions.\n",
      "Previous research has seen attempts to integrate language\n",
      "models into the field of veterinary science. General-purpose\n",
      "language models have been utilized, but their applicability\n",
      "within this domain is limited due to the specialized termi-\n",
      "nologies, anatomical complexities, and disease-specific nu-\n",
      "ances unique to veterinary medicine. The shortcomings of\n",
      "these models in handling veterinary-specific language and\n",
      "concepts have been well-documented. Efforts have been\n",
      "made to compile comprehensive datasets of veterinary ter-\n",
      "minologies and medical records to assist in the development\n",
      "of specialized language models. These datasets, often cu-\n",
      "rated from clinical records, textbooks, and research publi-\n",
      "cations, aim to capture the diverse and intricate terminolo-\n",
      "gies specific to animal anatomy, diseases, treatments, and\n",
      "clinical practices. Adaptations of general language mod-\n",
      "els, such as GPT and BERT, have been explored in the con-\n",
      "text of veterinary science. However, these adaptations have\n",
      "faced challenges in adequately addressing the specialized\n",
      "requirements of the veterinary domain. Despite attempts to\n",
      "fine-tune these models on veterinary datasets, their perfor-\n",
      "mance in generating contextually accurate and specialized\n",
      "veterinary content remains limited. Recent advancements\n",
      "have focused on developing specialized language models\n",
      "explicitly tailored to veterinary science. These models aim\n",
      "to fill the gap by comprehensively understanding and gener-ating veterinary-specific language, encompassing anatomi-\n",
      "cal structures, disease characteristics, treatments, and clin-\n",
      "ical practices. The emergence of such models represents\n",
      "a concerted effort to bridge the domain-specific gap be-\n",
      "tween natural language processing and veterinary medicine.\n",
      "While advancements have been made in developing spe-\n",
      "cialized language models for veterinary science, challenges\n",
      "persist. These include the scarcity of large-scale veterinary\n",
      "datasets, the need for model interpretability in clinical set-\n",
      "tings, and ensuring the ethical and responsible use of lan-\n",
      "guage models in veterinary practices. The ongoing work in\n",
      "this field presents an opportunity to revolutionize veterinary\n",
      "medicine by leveraging language models tailored explicitly\n",
      "for this domain.\n",
      "In recent strides within language model research, the in-\n",
      "troduction of Llama 2[3] marks a significant milestone in\n",
      "the realm of large language models (LLMs). This ground-\n",
      "breaking development comprises a series of meticulously\n",
      "crafted LLMs ranging from 7 billion to 70 billion param-\n",
      "eters. Among these, the Llama 2-Chat models are metic-\n",
      "ulously tailored for dialogue-driven applications. Through\n",
      "meticulous assessments, Llama 2-Chat demonstrates excep-\n",
      "tional performance, consistently outpacing existing open-\n",
      "source chat models across a spectrum of benchmarks. Par-\n",
      "ticularly notable is its proficiency in navigating diverse con-\n",
      "versational scenarios and nuances, showcasing remarkable\n",
      "adaptability within dialogue-based applications. Critical\n",
      "evaluations, focusing on aspects of helpfulness and safety,\n",
      "shed light on the potential of Llama 2-Chat as a viable alter-\n",
      "native to closed-source models. These evaluations suggest\n",
      "the suitability of Llama 2-Chat for practical deployment in\n",
      "various domains, affirming its robustness and applicabil-\n",
      "ity.To offer transparency and facilitate advancements in the\n",
      "field, a comprehensive exposition detailing the fine-tuning\n",
      "methodologies and rigorous safety enhancements integrated\n",
      "into Llama 2-Chat is presented.\n",
      "In natural language processing, adapting colossal pre-\n",
      "trained models like GPT-3 175B to specific tasks becomes\n",
      "challenging due to their size. To overcome this, Low-Rank\n",
      "Adaptation (LoRA)[1] introduces a method that signifi-\n",
      "cantly reduces trainable parameters while preserving model\n",
      "quality. By embedding trainable rank decomposition matri-\n",
      "ces into each layer of the Transformer architecture, LoRA\n",
      "achieves a remarkable reduction—10,000 times fewer train-\n",
      "able parameters and a 3x decrease in GPU memory re-\n",
      "quirement compared to fine-tuning GPT-3 175B. Despite\n",
      "this dramatic reduction, LoRA matches or surpasses model\n",
      "performance across diverse benchmarks. Notably, it does\n",
      "so without introducing additional inference latency, setting\n",
      "it apart as an efficient and effective adaptation technique.\n",
      "Low-Rank Adaptation (LoRA) proposes a solution by sub-\n",
      "stantially cutting down the number of trainable parameters\n",
      "while maintaining robust model performance. By integrat-ing trainable rank decomposition matrices into each layer\n",
      "of the Transformer architecture, LoRA achieves a drastic\n",
      "reduction—10,000 times fewer trainable parameters and a\n",
      "notable decrease of 3x in GPU memory requirements com-\n",
      "VetMedGPT: Generative Pre-trained Transformer for Enhanced Animal\n",
      "Healthcare\n",
      "Pinxue Lin Sayed Raheel Hussain Tirupathi Kadari\n",
      "plin3@mail.yu.edu shussai1@mail.yu.edu tkadari@mail.yu.edu\n",
      "Yeshiva University, NYC, NY\n",
      "Katz School of Science and Health\n",
      "Abstract\n",
      "This research outlines our current pursuit in crafting\n",
      "VetMedGPT, a specialized Generative Pre-trained Trans-\n",
      "former at the intersection of veterinary science and artifi-\n",
      "cial intelligence. Our focus centers on the dynamic integra-\n",
      "tion of advanced language models with datasets exceeding\n",
      "1 terabyte, meticulously enriched with information sourced\n",
      "from Wikipedia and veterinary science books. The dataset is\n",
      "curated to encapsulate diverse animal-related data, veteri-\n",
      "nary science nuances, and glossary-specific content. Our\n",
      "approach emphasizes an agile and iterative fine-tuning pro-\n",
      "cess for VetMedGPT. The model is intricately designed to\n",
      "comprehend and generate language specific to veterinary\n",
      "science, addressing nuanced terminologies critical for clin-\n",
      "ical support, progressive research, and elevated education\n",
      "in the field.\n",
      "This paper serves as a snapshot of our ongoing efforts,\n",
      "showcasing our commitment to seamlessly weave advanced\n",
      "AI capabilities with the wealth of information drawn from\n",
      "Wikipedia. The continuous evolution of VetMedGPT, driven\n",
      "by an enriched dataset, signifies our dedication to pushing\n",
      "the boundaries of artificial intelligence in the realm of vet-\n",
      "erinary science.\n",
      "1. Introduction\n",
      "In the dynamic realm of veterinary science, where the\n",
      "complexities of animal health intertwine with the evolving\n",
      "landscape of medical knowledge, VetMedGPT emerges as\n",
      "a beacon of transformative innovation. As a specialized\n",
      "Generative Pre-trained Transformer, VetMedGPT is metic-\n",
      "ulously designed to decipher and generate language specific\n",
      "to veterinary science, addressing the intricate terminolo-\n",
      "gies embedded in animal anatomy, diseases, treatments, and\n",
      "clinical practices. The motivation propelling the develop-\n",
      "ment of VetMedGPT is rooted in the recognition of thechallenges inherent in traditional approaches to veterinary\n",
      "medicine. The need for a sophisticated tool capable of nav-\n",
      "igating the vast and dynamic corpus of veterinary knowl-\n",
      "edge has never been more pressing. VetMedGPT not only\n",
      "fills this void but also endeavors to revolutionize the field\n",
      "by bridging the gap between complex medical conditions\n",
      "in animals and clinical decision-making. Beyond this, it\n",
      "stands as a catalyst for advancing research and elevating ed-\n",
      "ucational standards in veterinary science.\n",
      "Central to the efficacy of VetMedGPT is the ambitious\n",
      "initiative to curate a dataset exceeding 1 TB, comprising lit-\n",
      "erature and significant normal animal data. This dataset,\n",
      "drawn from diverse sources including Wikipedia and vet-\n",
      "erinary science-related books, encompasses titles related\n",
      "to the field, animal-specific subjects, and diseases associ-\n",
      "ated with animals. Test data for veterinary science ex-\n",
      "ams such as the Veterinary College Admission Test (VCAT)\n",
      "and the North American Veterinary Licensing Examination\n",
      "(NA VLE) will be utilized. The richness and diversity of\n",
      "this dataset serve as the foundation for the comprehensive\n",
      "training of VetMedGPT, leveraging a large-scale generative\n",
      "language model.\n",
      "2. Related Work\n",
      "The field of veterinary medicine grapples with a myr-\n",
      "iad of challenges pertaining to the interpretation and anal-\n",
      "ysis of highly specialized terminologies, intricate animal\n",
      "anatomical structures, and nuanced disease manifestations.\n",
      "Traditional natural language processing (NLP) models of-\n",
      "ten fall short of comprehensively addressing these spe-\n",
      "cific veterinary requirements, thereby creating a signifi-\n",
      "cant barrier between conventional language models and\n",
      "the intricate domain of veterinary science. Some efforts\n",
      "have been made in the past to bridge this gap by adapt-\n",
      "ing general-purpose language models for veterinary appli-\n",
      "cations. However, these adaptations have generally lacked\n",
      "the depth, precision, and specialization necessary to com-prehensively handle the breadth of veterinary terminologies\n",
      "and complexities. The inadequacies in existing models have\n",
      "led to limitations in accurately processing, understanding,\n",
      "and generating contextually relevant content for veterinary\n",
      "medicine. In response to these limitations, our research\n",
      "introduces VetMedGPT, a highly specialized Generative\n",
      "Pre-trained Transformer (GPT) model expressly tailored to\n",
      "the unique demands of veterinary science. VetMedGPT is\n",
      "meticulously designed to overcome the challenges posed\n",
      "by the intricate language, complex anatomical structures,\n",
      "and diverse medical nuances within the veterinary domain.\n",
      "By utilizing a large-scale dataset of professional literature\n",
      "and comprehensive animal data for training, VetMedGPT\n",
      "aims to offer a groundbreaking solution that comprehen-\n",
      "sively understands and generates veterinary-specific lan-\n",
      "guage and concepts. The development of VetMedGPT is\n",
      "driven by a critical need within the veterinary community\n",
      "for a sophisticated, domain-specific language model capa-\n",
      "packing and padding. The adaptation was executed using\n",
      "LoRA (Low-Rank Adaptation).3.3.2 Training and Optimization\n",
      "The training was configured with gradient accumulation\n",
      "steps of 4 and a micro-batch size of 2, spanning a single\n",
      "epoch. We utilized adamwas the optimizer, with a learn-\n",
      "ing rate of 0.0002, and a cosine learning rate scheduler. For\n",
      "precision training, BF16 was enabled, supplemented by gra-\n",
      "dient checkpointing and flash attention.\n",
      "4. Results\n",
      "4.1. Datasets\n",
      "5. Discussion\n",
      "6. Conclusion\n",
      "References\n",
      "[1] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,\n",
      "Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora:\n",
      "Low-rank adaptation of large language models. arXiv preprint\n",
      "arXiv:2106.09685 , 2021. 2\n",
      "[2] Yixing Jiang, Jeremy A Irvin, Andrew Y Ng, and James Zou.\n",
      "Vetllm: Large language model for predicting diagnosis from\n",
      "veterinary notes. 2023. 3\n",
      "[3] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Am-\n",
      "jad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya\n",
      "Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2:\n",
      "Open foundation and fine-tuned chat models. arXiv preprint\n",
      "arXiv:2307.09288 , 2023. 2\n",
      "[4] Guangyu Wang, Guoxing Yang, Zongxin Du, Longjun Fan,\n",
      "and Xiaohu Li. Clinicalgpt: Large language models fine-\n",
      "tuned with diverse medical data and comprehensive evalua-\n",
      "tion. arXiv preprint arXiv:2306.09968 , 2023. 3\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSenior_Python_Engineer\u001b[0m (to chat_manager):\n",
      "\n",
      "I'm sorry, but I cannot summarize the content of a PDF file without access to the actual file. Please provide the PDF file or specify the specific information you would like me to summarize.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_Manager\u001b[0m (to chat_manager):\n",
      "\n",
      "UPDATE CONTEXT\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCode_Reviewer\u001b[0m (to chat_manager):\n",
      "\n",
      "I apologize for the confusion. Based on the provided context, the content seems to be discussing the development of VetMedGPT, a specialized Generative Pre-trained Transformer model for veterinary science. The motivation behind VetMedGPT is to revolutionize veterinary medicine by improving clinical decision-making, research literature analysis, and educational endeavors in the field. The content also mentions the challenges of integrating general-purpose language models into veterinary science due to the specialized terminologies and nuances unique to the field. Efforts have been made to develop specialized language models tailored explicitly to veterinary science. Additionally, the content briefly mentions the introduction of Llama 2, a large language model, and Low-Rank Adaptation (LoRA), a method to reduce trainable parameters while preserving model quality. These advancements aim to enhance the performance and efficiency of language models in veterinary science.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mBoss_Assistant\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSenior_Python_Engineer\u001b[0m (to chat_manager):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "boss_aid.initiate_chat(\n",
    "        manager,\n",
    "        problem=PROBLEM,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
